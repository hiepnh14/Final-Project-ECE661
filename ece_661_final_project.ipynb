{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#The first three cells of this notebook are the beginning of a solution to get a better version of ResNet18 (and VGG19) for the CIFAR-10 dataset. I (Jack) didn't finish this, so please continue on. You should be able to run these cells and generate a state_dict for any image classifier you'd like.\n",
        "\n",
        "#I have already trained ResNet18 up to above 85% accuracy on CIFAR-10. I included the checkpoint in the repo. We just need someone to train VGG19 (the model we're going to transfer our attack to) for about 75 epochs\n",
        "\n",
        "#Before running our experiments, we should make sure we can attack this version of ResNet. You may need to modify the cells below the first three cells in order to get the attack to work with this new version of ResNet (for example, the CIFAR-10 datasets used to train and validate the ResNet in the below 3 cells is different from the CIFAR-10 datasets I use in the rest of the notebook. You should modify any later cells to work with this better version of ResNet18. Let me know if you have any questions about the code!"
      ],
      "metadata": {
        "id": "ubL46wu-CJJb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the git repository for PyTorch models optimized for performance on CIFAR-10\n",
        "# Reference: https://github.com/kuangliu/pytorch-cifar\n",
        "!rm -rf /content/pytorch-cifar\n",
        "!git clone https://github.com/kuangliu/pytorch-cifar.git\n",
        "%cd /content/pytorch-cifar/"
      ],
      "metadata": {
        "id": "sM5ktRhuLFty",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60c2dac2-8188-4d5e-a0b7-02f62fd382ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pytorch-cifar'...\n",
            "remote: Enumerating objects: 382, done.\u001b[K\n",
            "remote: Total 382 (delta 0), reused 0 (delta 0), pack-reused 382\u001b[K\n",
            "Receiving objects: 100% (382/382), 81.31 KiB | 2.62 MiB/s, done.\n",
            "Resolving deltas: 100% (198/198), done.\n",
            "/content/pytorch-cifar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the main function from the above repo to train a model to >80% accuracy on CIFAR-10\n",
        "\n",
        "#####################################################################################################\n",
        "\n",
        "# IMPORTANT!!! Modify main.py so that the training runs for only 75 epochs. Otherwise, it will train for 200 epochs!\n",
        "# IMPORTANT!!! For Experiment #1 and Experiment #2, modify main.py so that you train ResNet18\n",
        "# IMPORTANT!!! For Experiment #3, modify main.py so that you ALSO train VGG19 (will need to run this cell twice, once for ResNet 18 and once for ResNet50)\n",
        "\n",
        "#####################################################################################################\n",
        "\n",
        "!python main.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQNNkW00PCT6",
        "outputId": "eea1945c-3a07-46c9-8209-6f278b303658"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Preparing data..\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n",
            "100% 170498071/170498071 [00:02<00:00, 70791676.78it/s]\n",
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "==> Building model..\n",
            "\n",
            "Epoch: 0\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            " [================================================================>]  Step: 2s517ms | Tot: 1m5s | Loss: 1.740 | Acc: 35.042% (17521/50000) 391/391 \n",
            " [================================================================>]  Step: 40ms | Tot: 4s127ms | Loss: 1.541 | Acc: 43.740% (4374/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 1\n",
            " [================================================================>]  Step: 102ms | Tot: 1m2s | Loss: 1.302 | Acc: 52.820% (26410/50000) 391/391 \n",
            " [================================================================>]  Step: 40ms | Tot: 4s170ms | Loss: 1.197 | Acc: 56.880% (5688/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 2\n",
            " [================================================================>]  Step: 102ms | Tot: 1m2s | Loss: 1.036 | Acc: 63.292% (31646/50000) 391/391 \n",
            " [================================================================>]  Step: 40ms | Tot: 4s324ms | Loss: 1.240 | Acc: 58.970% (5897/10000) 100/100 \n",
            "Saving..\n",
            "\n",
            "Epoch: 3\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/pytorch-cifar/main.py\", line 152, in <module>\n",
            "    train(epoch)\n",
            "  File \"/content/pytorch-cifar/main.py\", line 104, in train\n",
            "    loss.backward()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\", line 522, in backward\n",
            "    torch.autograd.backward(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\", line 266, in backward\n",
            "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate our model(s)\n",
        "from models import *\n",
        "\n",
        "state_dict = torch.load(\"/content/pytorch-cifar/checkpoint/VGG19.pth\")[\"net\"]\n",
        "\n",
        "# Reference: https://discuss.pytorch.org/t/solved-keyerror-unexpected-key-module-encoder-embedding-weight-in-state-dict/1686/3\n",
        "from collections import OrderedDict\n",
        "new_state_dict = OrderedDict()\n",
        "for k, v in state_dict.items():\n",
        "  name = k[7:] # remove `module.`\n",
        "  new_state_dict[name] = v\n",
        "\n",
        "model = VGG(\"VGG19\")\n",
        "model.load_state_dict(new_state_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwwAid5FSKPo",
        "outputId": "c6a3e183-1b7d-4a64-aedc-21475a48b421"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The cells below this point stand on their own. Run these cells to do a targeted/untargeted patch attack on a weaker version of ResNet18 (~65% accuracy before the attack). Again, the code in the rest of the notebook may need to be modified in order to work with the stronger version of ResNet18 (definitely the dataset used below should be changed to the dataset used above - they're both CIFAR10, but the dataset above uses different image preprocessing)."
      ],
      "metadata": {
        "id": "H07PJgOYB5T4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmkvJUdW5n7r",
        "outputId": "862cb7d6-156e-4dbb-f10b-33615ebbc8a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "import torchvision.transforms.functional as TF\n",
        "import random\n",
        "import tqdm\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCBcpnKjcD9N",
        "outputId": "1158c817-6f05-43e2-9f2f-55925133e636"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# Load dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "cifar_10 = datasets.CIFAR10(root=\"./data\",\n",
        "                            train=True,\n",
        "                            download=True,\n",
        "                            transform=transform)\n",
        "\n",
        "# Split into training, val, and test sets\n",
        "train, test_set = random_split(cifar_10, [40000, 10000])\n",
        "train_set, val_set = random_split(train, [35000, 5000])\n",
        "\n",
        "# Define dataloaders\n",
        "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_set, batch_size=32, shuffle=False)\n",
        "\n",
        "# Load pre-trained model\n",
        "resnet18 = models.resnet18(weights=\"DEFAULT\")\n",
        "\n",
        "# ResNet is trained on ImageNet, which has 1000 classes\n",
        "# So we need to modify the output layer for CIFAR-10, which has 10 classes\n",
        "resnet18.fc = nn.Linear(resnet18.fc.in_features, 10)\n",
        "\n",
        "# We also need to modify the input layer to accept CIFAR-10 images\n",
        "first_layer = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3)\n",
        "resnet18.conv1 = first_layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9a2zDi55-lG1"
      },
      "outputs": [],
      "source": [
        "# This function evaluates a model's accuracy on the validation set\n",
        "# Optionally, one can pass an adversarial patch as an argument to evaluate the model's performance against a patch attack\n",
        "def eval(model, patch=None, target_class=None):\n",
        "  # Stats to use to calculate accuracy after the eval loop\n",
        "  total_correct = 0\n",
        "  total = 0\n",
        "  total_target = 0\n",
        "  # Put model on GPU and switch to eval mode\n",
        "  model = model.to(device)\n",
        "  model.eval()\n",
        "  # Evaluation loop\n",
        "  with torch.no_grad():\n",
        "    for batch_idx, (images, labels) in enumerate(val_loader):\n",
        "      # Put data on GPU\n",
        "      images = images.to(device)\n",
        "      if patch is not None:\n",
        "        images = apply(patch, images)\n",
        "      labels = labels.to(device)\n",
        "      # Make predictions\n",
        "      predictions = model(images)\n",
        "      predictions = torch.argmax(predictions, dim=1)\n",
        "      # Update validation accuracy information\n",
        "      total += len(images)\n",
        "      num_correct = (predictions == labels).float().sum().item()\n",
        "      total_correct += num_correct\n",
        "      if target_class is not None:\n",
        "        target = torch.zeros(len(images), dtype=torch.long).fill_(target_class).to(device)\n",
        "        num_target = (predictions == target).float().sum().item()\n",
        "        total_target += num_target\n",
        "  # If evaluating the effects of a targeted patch attach, it is nice to see whether or not the model is classifying lots of examples to the target class\n",
        "  if target_class is not None:\n",
        "    target_percentage = total_target / total\n",
        "    print(f\"Percentage of samples predicted as target class {target_class}: {100 * target_percentage}\")\n",
        "  # Calculate accuracy\n",
        "  accuracy = total_correct / total\n",
        "  return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "qO7Fij4HzwZ6",
        "outputId": "aba20752-79d8-4e75-dbcf-c710de136762"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Training accuracy = 0.28454285714285715\n",
            "Validation accuracy: 0.3652\n",
            "Epoch 2: Training accuracy = 0.4175142857142857\n",
            "Validation accuracy: 0.4798\n",
            "Epoch 3: Training accuracy = 0.5023428571428571\n",
            "Validation accuracy: 0.534\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-712daa7cc693>\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# Applying the function above to ResNet18\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mfine_tune_for_cifar10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet18\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-712daa7cc693>\u001b[0m in \u001b[0;36mfine_tune_for_cifar10\u001b[0;34m(model, num_epochs)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Iterate through each batch of data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m       \u001b[0;31m# Put data on GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m       \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__getitems__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;31m# see torch.utils.data._utils.fetch._MapDatasetFetcher\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__getitems__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;31m# doing this so that it is consistent with all other datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# to return a PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   3097\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstrides\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3098\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tobytes\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3099\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3100\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3101\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# This function is designed to take in a pretrained ResNet model and fine-tune its weights for the CIFAR-10 dataset\n",
        "# The idea is to fine-tune ResNet for the CIFAR-10 dataset (accuracy should be around 65%) and then degrade that performance via an adversarial patch attack\n",
        "def fine_tune_for_cifar10(model, num_epochs=10):\n",
        "  # Put model on GPU and put model in training mode\n",
        "  model = model.to(device)\n",
        "  model.train()\n",
        "  # Define loss function and optimizer\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
        "  # Training loop\n",
        "  for i in range(num_epochs):\n",
        "    # Stats to use for calculating accuracy\n",
        "    total_correct = 0\n",
        "    total = 0\n",
        "    # Iterate through each batch of data\n",
        "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "      # Put data on GPU\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "      # Make predictions\n",
        "      predictions = model(images)\n",
        "      # Calculate loss for the batch\n",
        "      loss = criterion(predictions, labels)\n",
        "      # Gradient descent\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      # Update training accuracy information\n",
        "      total += len(images)\n",
        "      predictions = torch.argmax(predictions, dim=1)\n",
        "      num_correct = (predictions == labels).float().sum().item()\n",
        "      total_correct += num_correct\n",
        "    # Print training accuracy\n",
        "    print(f\"Epoch {str(i + 1)}: Training accuracy = {str(total_correct / total)}\")\n",
        "    # Print validation accuracy\n",
        "    print(f\"Validation accuracy: {str(eval(model))}\")\n",
        "\n",
        "# Applying the function above to ResNet18\n",
        "fine_tune_for_cifar10(resnet18)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c76F8SAkdz3b"
      },
      "outputs": [],
      "source": [
        "# Apply patch to a batch of images\n",
        "def apply(patch, batch_of_images):\n",
        "  num_images = batch_of_images.shape[0]\n",
        "  patch_size = patch.shape[1]\n",
        "  # Iterate through each image in the batch\n",
        "  for i in range(num_images):\n",
        "    # Rotate the patch by a random number of degrees\n",
        "    degree = random.uniform(0, 360)\n",
        "    patch_rotated = TF.rotate(patch, angle=degree)\n",
        "    # Randomly choose an (x, y) coordinate on the 32x32 CIFAR-10 image\n",
        "    # This coordinate will be where the top left corner of the rotated patch goes\n",
        "    top_left_x = random.randint(0, 31 - patch_size)\n",
        "    top_left_y = random.randint(0, 31 - patch_size)\n",
        "    # Apply the randomly rotated patch at the random location\n",
        "    batch_of_images[i, :, top_left_x:top_left_x+patch_size, top_left_y:top_left_y+patch_size] = patch\n",
        "  return batch_of_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bPgstLQ6hfO"
      },
      "outputs": [],
      "source": [
        "# This function fine-tunes an adversarial patch against a provided whitebox model\n",
        "# Model accuracy against the patch attack is reported at each step\n",
        "def generate_adversarial_patch(model=resnet18, patch_size=8, target_class=None, num_epochs=10, lr=1e-1, momentum=0.8):\n",
        "  # Initialize patch to all zeros\n",
        "  patch = nn.Parameter(torch.zeros(3, patch_size, patch_size), requires_grad=True)\n",
        "  optimizer = optim.SGD([patch], lr, momentum)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  # Optimize the patch\n",
        "  for i in range(num_epochs):\n",
        "    print(f\"Epoch {str(i + 1)}\")\n",
        "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "      # Put data on the GPU\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "      # Apply the patch at a random location and with a random rotation for each image in the batch\n",
        "      images = apply(patch, images)\n",
        "      # Make predictions on the patched images\n",
        "      predictions = resnet18(images)\n",
        "      # For an untargeted attack, create false labels by incrementing the true labels by 1\n",
        "      if target_class is None:\n",
        "        false_labels = (labels + 1) % 10\n",
        "      # For a targeted attack, set all the false labels to the target class\n",
        "      else:\n",
        "        false_labels = torch.zeros(len(images), dtype=torch.long).fill_(target_class).to(device)\n",
        "      # Tune the patch\n",
        "      loss = criterion(predictions, false_labels)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    # See how the patch performs\n",
        "    print(f\"Target class: {target_class}\")\n",
        "    accuracy = eval(model, patch=patch, target_class=target_class)\n",
        "    print(f\"Accuracy: {str(accuracy)}\\n\")\n",
        "\n",
        "generate_adversarial_patch(target_class=5)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}